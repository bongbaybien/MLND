{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_memo = '''\n",
    "Milt, we're gonna need to go ahead and move you downstairs into storage B. We have some new people coming in, and we need all the space we can get. So if you could just go ahead and pack up your stuff and move it down there, that would be terrific, OK?\n",
    "Oh, and remember: next Friday... is Hawaiian shirt day. So, you know, if you want to, go ahead and wear a Hawaiian shirt and jeans.\n",
    "Oh, oh, and I almost forgot. Ahh, I'm also gonna need you to go ahead and come in on Sunday, too...\n",
    "Hello Peter, whats happening? Ummm, I'm gonna need you to go ahead and come in tomorrow. So if you could be here around 9 that would be great, mmmk... oh oh! and I almost forgot ahh, I'm also gonna need you to go ahead and come in on Sunday too, kay. We ahh lost some people this week and ah, we sorta need to play catch up.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def NextWordProbability(sampletext,word):\n",
    "    '''\n",
    "    return count\n",
    "    '''\n",
    "    words = sampletext.split()\n",
    "    indices = [i for i, w in enumerate(words) if w==word]\n",
    "    nextwords = [words[i+1] for i in indices]\n",
    "    \n",
    "    word_dict = {}\n",
    "    for w in set(nextwords):\n",
    "        word_dict[w] = nextwords.count(w)\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'go': 4, 'play': 1}\n",
      "{'ahead': 6}\n"
     ]
    }
   ],
   "source": [
    "print NextWordProbability(sample_memo, 'to')\n",
    "print NextWordProbability(sample_memo, 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def NextWordProbability(sampletext,word):\n",
    "    '''\n",
    "    return probability\n",
    "    '''\n",
    "    words = sampletext.split()\n",
    "    indices = [i for i, w in enumerate(words) if w==word]\n",
    "    nextwords = [words[i+1] for i in indices]\n",
    "    \n",
    "    word_dict = {}\n",
    "    for w in set(nextwords):\n",
    "        word_dict[w] = float(nextwords.count(w))/float(len(nextwords))\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'go': 0.8, 'play': 0.2}\n",
      "{'ahead': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print NextWordProbability(sample_memo, 'to')\n",
    "print NextWordProbability(sample_memo, 'go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LaterWords(sample,word,distance):\n",
    "    '''@param sample: a sample of text to draw from\n",
    "    @param word: a word occuring before a corrupted sequence\n",
    "    @param distance: how many words later to estimate (i.e. 1 for the next word, 2 for the word after that)\n",
    "    @returns: a single word which is the most likely possibility\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    The function has two basic step\n",
    "    1- Find the next words and their probability of ocurring, aka the \"likelihood\"\n",
    "    2- Find the posterior probablity for each word\n",
    "    \n",
    "    To do this, the function does the following:\n",
    "    - For each iteration up to @param distance:\n",
    "        - find the nextword_dict (this is the likelihood)\n",
    "        - multiply with prior_dict to find post_dict\n",
    "        - During the 1st iteration, prior_dict is initialized with the given word and prob of 1\n",
    "        - From the 2nd iteration on, post_dict becomes prior_dict at the start of each loop, and post_dict is emptied out\n",
    "    '''\n",
    "        \n",
    "    #initialize    \n",
    "    prior_dict = {word: 1}\n",
    "    \n",
    "    for dist in range(distance):        \n",
    "        post_dict = {}\n",
    "        \n",
    "        for pw in prior_dict:\n",
    "            nextword_dict = NextWordProbability(sample, pw)\n",
    "        \n",
    "            for nw in nextword_dict:\n",
    "                if nw not in post_dict:\n",
    "                    post_dict[nw] = nextword_dict[nw] * prior_dict[pw]\n",
    "                else:\n",
    "                    post_dict[nw] = post_dict[nw] + nextword_dict[nw] * prior_dict[pw]\n",
    "        \n",
    "        prior_dict = post_dict\n",
    "                                               \n",
    "#     return post_dict #return dictionary of word and probability\n",
    "    return max(post_dict, key=post_dict.get) # return word with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'go': 0.8, 'play': 0.2}\n",
      "{'ahead': 1.0}\n",
      "{'catch': 1.0}\n",
      "{'catch': 0.2, 'ahead': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print LaterWords(sample_memo, 'to', 1)\n",
    "print LaterWords(sample_memo, 'go', 1)\n",
    "print LaterWords(sample_memo, 'play', 1)\n",
    "print LaterWords(sample_memo, 'to', 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
