{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import helper\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dropout, Dense\n",
    "from keras import optimizers\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data, format, & preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotion_dict = {0:'angry', 1:'disgust', 2:'fear', 3:'happy', 4:'sad', 5:'surprise', 6:'neutral'}\n",
    "image_shape = (48,48,1)\n",
    "n_classes = len(emotion_dict)\n",
    "n_features = np.product(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "file_path = './Data/Kaggle-FER/fer2013.csv'\n",
    "data_raw = helper.read_in_data(file_path) # data is a tuple of (x_list, y_list, usage_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert data to numpy array\n",
    "data_formatted = helper.format(data_raw, image_shape, n_classes) # return tuple of (x_array, y_array, usage_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4945, 1: 547, 2: 5121, 3: 8988, 4: 6076, 5: 4001, 6: 6197}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of example for each class\n",
    "label, count = np.unique(data_formatted[1], return_counts=True)\n",
    "dict(zip(label, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train & test sets. Test set = public, private set is used for final testing, to be consistent with the competition\n",
    "(x_train, y_train), (x_test, y_test), (x_private, y_private) = helper.create_train_test(data_formatted, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "y_train_onehot = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, n_classes)\n",
    "y_private_onehot = keras.utils.to_categorical(y_private, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28698, 48, 48, 1)\n",
      "(28698, 1)\n",
      "(28698, 7)\n",
      "(3588, 48, 48, 1)\n",
      "(3588, 1)\n",
      "(3588, 7)\n",
      "(3589, 48, 48, 1)\n",
      "(3589, 1)\n",
      "(3589, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train_onehot.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_test_onehot.shape)\n",
    "print(x_private.shape)\n",
    "print(y_private.shape)\n",
    "print(y_private_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Python35-64bit\\lib\\site-packages\\keras\\preprocessing\\image.py:648: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (28698, 48, 48, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n",
      "C:\\Program Files (x86)\\Python35-64bit\\lib\\site-packages\\keras\\preprocessing\\image.py:648: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (3588, 48, 48, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "# preprocess: normalized\n",
    "train_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "test_datagen.fit(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e0b47960b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visual data\n",
    "index = 8\n",
    "\n",
    "img_array = np.reshape(x_train[index], (48,48))\n",
    "plt.imshow(img_array, cmap='gray')\n",
    "print(emotion_dict[y_train[index,0]])\n",
    "\n",
    "# after preprocess\n",
    "i = 0\n",
    "for batch in train_datagen.flow(np.reshape(x_train[index], (1,*image_shape))\n",
    "                                , batch_size=32, save_to_dir='preview', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 20)        340       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 20)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 11520)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11520)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               1152100   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 1,153,147\n",
      "Trainable params: 1,153,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# simple model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, (4,4), padding='same', activation='relu', input_shape=image_shape))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2), padding='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 256\n",
    "n_train = len(x_train)\n",
    "n_test = len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "112/112 [==============================] - 40s - loss: 1.7177 - acc: 0.3333 - val_loss: 1.5945 - val_acc: 0.3892\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 38s - loss: 1.5364 - acc: 0.4175 - val_loss: 1.5084 - val_acc: 0.4172\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 38s - loss: 1.4574 - acc: 0.4489 - val_loss: 1.4496 - val_acc: 0.4400\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 38s - loss: 1.4048 - acc: 0.4686 - val_loss: 1.4296 - val_acc: 0.4577\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 39s - loss: 1.3629 - acc: 0.4877 - val_loss: 1.3948 - val_acc: 0.4745\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 38s - loss: 1.3274 - acc: 0.5016 - val_loss: 1.3927 - val_acc: 0.4696\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 38s - loss: 1.2848 - acc: 0.5197 - val_loss: 1.3920 - val_acc: 0.4682\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 38s - loss: 1.2602 - acc: 0.5255 - val_loss: 1.3830 - val_acc: 0.4730\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 38s - loss: 1.2308 - acc: 0.5383 - val_loss: 1.3727 - val_acc: 0.4895\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 38s - loss: 1.2056 - acc: 0.5461 - val_loss: 1.4106 - val_acc: 0.4604\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 38s - loss: 1.1785 - acc: 0.5614 - val_loss: 1.3971 - val_acc: 0.4749\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 39s - loss: 1.1503 - acc: 0.5672 - val_loss: 1.3997 - val_acc: 0.4814\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 38s - loss: 1.1388 - acc: 0.5743 - val_loss: 1.4078 - val_acc: 0.4796\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - 38s - loss: 1.1193 - acc: 0.5856 - val_loss: 1.4133 - val_acc: 0.4850\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 38s - loss: 1.0966 - acc: 0.5907 - val_loss: 1.3968 - val_acc: 0.4820\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 38s - loss: 1.0850 - acc: 0.5945 - val_loss: 1.4163 - val_acc: 0.4891\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 38s - loss: 1.0560 - acc: 0.6059 - val_loss: 1.4199 - val_acc: 0.4736\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 38s - loss: 1.0382 - acc: 0.6157 - val_loss: 1.4279 - val_acc: 0.4874\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 38s - loss: 1.0214 - acc: 0.6204 - val_loss: 1.4253 - val_acc: 0.4871\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 38s - loss: 1.0150 - acc: 0.6243 - val_loss: 1.4763 - val_acc: 0.4727\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 38s - loss: 0.9962 - acc: 0.6311 - val_loss: 1.4465 - val_acc: 0.4863\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 38s - loss: 0.9805 - acc: 0.6356 - val_loss: 1.4403 - val_acc: 0.4898\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 38s - loss: 0.9758 - acc: 0.6358 - val_loss: 1.4687 - val_acc: 0.4835\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 38s - loss: 0.9503 - acc: 0.6464 - val_loss: 1.4805 - val_acc: 0.4874\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 38s - loss: 0.9410 - acc: 0.6505 - val_loss: 1.4991 - val_acc: 0.4865\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 38s - loss: 0.9336 - acc: 0.6546 - val_loss: 1.4855 - val_acc: 0.4813\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 38s - loss: 0.9142 - acc: 0.6627 - val_loss: 1.4967 - val_acc: 0.4829\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 38s - loss: 0.9040 - acc: 0.6658 - val_loss: 1.5047 - val_acc: 0.4898\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 38s - loss: 0.8869 - acc: 0.6710 - val_loss: 1.4937 - val_acc: 0.4931\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 38s - loss: 0.8693 - acc: 0.6795 - val_loss: 1.5387 - val_acc: 0.4841\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 38s - loss: 0.8683 - acc: 0.6755 - val_loss: 1.5215 - val_acc: 0.4863\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 38s - loss: 0.8632 - acc: 0.6791 - val_loss: 1.5667 - val_acc: 0.4805\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 38s - loss: 0.8389 - acc: 0.6904 - val_loss: 1.5297 - val_acc: 0.4832\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 38s - loss: 0.8404 - acc: 0.6875 - val_loss: 1.5760 - val_acc: 0.4823\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 38s - loss: 0.8230 - acc: 0.6955 - val_loss: 1.5485 - val_acc: 0.4889\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 38s - loss: 0.8106 - acc: 0.6978 - val_loss: 1.6036 - val_acc: 0.4833\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 38s - loss: 0.8063 - acc: 0.6983 - val_loss: 1.6072 - val_acc: 0.4901\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 38s - loss: 0.8052 - acc: 0.7026 - val_loss: 1.6135 - val_acc: 0.4871\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 38s - loss: 0.7915 - acc: 0.7060 - val_loss: 1.6187 - val_acc: 0.4913\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 38s - loss: 0.7809 - acc: 0.7089 - val_loss: 1.6128 - val_acc: 0.4850\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 38s - loss: 0.7785 - acc: 0.7117 - val_loss: 1.6350 - val_acc: 0.4799\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 38s - loss: 0.7484 - acc: 0.7219 - val_loss: 1.7121 - val_acc: 0.4667\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 38s - loss: 0.7576 - acc: 0.7178 - val_loss: 1.6419 - val_acc: 0.4871\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 38s - loss: 0.7428 - acc: 0.7206 - val_loss: 1.6893 - val_acc: 0.4811\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 39s - loss: 0.7324 - acc: 0.7311 - val_loss: 1.7083 - val_acc: 0.4799\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 44s - loss: 0.7209 - acc: 0.7331 - val_loss: 1.6994 - val_acc: 0.4796\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 40s - loss: 0.7148 - acc: 0.7351 - val_loss: 1.7836 - val_acc: 0.4694\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 38s - loss: 0.7120 - acc: 0.7378 - val_loss: 1.7294 - val_acc: 0.4769\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 38s - loss: 0.7019 - acc: 0.7403 - val_loss: 1.7230 - val_acc: 0.4721\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 38s - loss: 0.7099 - acc: 0.7372 - val_loss: 1.7487 - val_acc: 0.4700\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 37s - loss: 0.6907 - acc: 0.7436 - val_loss: 1.7584 - val_acc: 0.4819\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 37s - loss: 0.6881 - acc: 0.7442 - val_loss: 1.8176 - val_acc: 0.4814\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 37s - loss: 0.6733 - acc: 0.7549 - val_loss: 1.7949 - val_acc: 0.4766\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 37s - loss: 0.6708 - acc: 0.7527 - val_loss: 1.8022 - val_acc: 0.4856\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 37s - loss: 0.6567 - acc: 0.7596 - val_loss: 1.7990 - val_acc: 0.4772\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 37s - loss: 0.6543 - acc: 0.7584 - val_loss: 1.8044 - val_acc: 0.4830\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 37s - loss: 0.6532 - acc: 0.7590 - val_loss: 1.8561 - val_acc: 0.4703\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 37s - loss: 0.6477 - acc: 0.7606 - val_loss: 1.8549 - val_acc: 0.4739\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 37s - loss: 0.6417 - acc: 0.7618 - val_loss: 1.8620 - val_acc: 0.4817\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 37s - loss: 0.6348 - acc: 0.7666 - val_loss: 1.9246 - val_acc: 0.4694\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 37s - loss: 0.6311 - acc: 0.7656 - val_loss: 1.8882 - val_acc: 0.4643\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 37s - loss: 0.6285 - acc: 0.7665 - val_loss: 1.9218 - val_acc: 0.4781\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 37s - loss: 0.6278 - acc: 0.7693 - val_loss: 1.9014 - val_acc: 0.4853\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 37s - loss: 0.6182 - acc: 0.7734 - val_loss: 1.9668 - val_acc: 0.4748\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 37s - loss: 0.6094 - acc: 0.7750 - val_loss: 1.9263 - val_acc: 0.4673\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 36s - loss: 0.6032 - acc: 0.7764 - val_loss: 1.9102 - val_acc: 0.4849\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 37s - loss: 0.6025 - acc: 0.7792 - val_loss: 1.9429 - val_acc: 0.4748\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 36s - loss: 0.5919 - acc: 0.7815 - val_loss: 1.9306 - val_acc: 0.4814\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 36s - loss: 0.5897 - acc: 0.7811 - val_loss: 1.9652 - val_acc: 0.4769\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 36s - loss: 0.5802 - acc: 0.7887 - val_loss: 1.9732 - val_acc: 0.4742\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 36s - loss: 0.5862 - acc: 0.7829 - val_loss: 1.9728 - val_acc: 0.4718\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 36s - loss: 0.5732 - acc: 0.7870 - val_loss: 2.0066 - val_acc: 0.4748\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 36s - loss: 0.5784 - acc: 0.7869 - val_loss: 2.0022 - val_acc: 0.4805\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 37s - loss: 0.5709 - acc: 0.7914 - val_loss: 2.0134 - val_acc: 0.4802\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 36s - loss: 0.5636 - acc: 0.7909 - val_loss: 2.0774 - val_acc: 0.4703\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 36s - loss: 0.5567 - acc: 0.7933 - val_loss: 2.0132 - val_acc: 0.4752\n",
      "Epoch 77/100\n",
      "112/112 [==============================] - 37s - loss: 0.5665 - acc: 0.7930 - val_loss: 1.9722 - val_acc: 0.4757\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 36s - loss: 0.5555 - acc: 0.7940 - val_loss: 2.0272 - val_acc: 0.4700\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 36s - loss: 0.5562 - acc: 0.7938 - val_loss: 2.1058 - val_acc: 0.4613\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 36s - loss: 0.5482 - acc: 0.7974 - val_loss: 2.1239 - val_acc: 0.4802\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 37s - loss: 0.5476 - acc: 0.7998 - val_loss: 2.0808 - val_acc: 0.4754\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 36s - loss: 0.5371 - acc: 0.8026 - val_loss: 2.0927 - val_acc: 0.4805\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 37s - loss: 0.5388 - acc: 0.8000 - val_loss: 2.0648 - val_acc: 0.4769\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 37s - loss: 0.5311 - acc: 0.8047 - val_loss: 2.1452 - val_acc: 0.4637\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 36s - loss: 0.5181 - acc: 0.8097 - val_loss: 2.1670 - val_acc: 0.4637\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 36s - loss: 0.5275 - acc: 0.8080 - val_loss: 2.1004 - val_acc: 0.4805\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 37s - loss: 0.5195 - acc: 0.8112 - val_loss: 2.2351 - val_acc: 0.4649\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 36s - loss: 0.5239 - acc: 0.8084 - val_loss: 2.1374 - val_acc: 0.4745\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 36s - loss: 0.5155 - acc: 0.8110 - val_loss: 2.1200 - val_acc: 0.4820\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 37s - loss: 0.5080 - acc: 0.8135 - val_loss: 2.1080 - val_acc: 0.4778\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 40s - loss: 0.5073 - acc: 0.8144 - val_loss: 2.1709 - val_acc: 0.4704\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 42s - loss: 0.5207 - acc: 0.8089 - val_loss: 2.1345 - val_acc: 0.4784\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 42s - loss: 0.5078 - acc: 0.8156 - val_loss: 2.1913 - val_acc: 0.4745\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 38s - loss: 0.5046 - acc: 0.8146 - val_loss: 2.1926 - val_acc: 0.4772\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 38s - loss: 0.4919 - acc: 0.8193 - val_loss: 2.2164 - val_acc: 0.4778\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 38s - loss: 0.4878 - acc: 0.8209 - val_loss: 2.1843 - val_acc: 0.4752\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 38s - loss: 0.4837 - acc: 0.8231 - val_loss: 2.2035 - val_acc: 0.4676\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 38s - loss: 0.4917 - acc: 0.8203 - val_loss: 2.1649 - val_acc: 0.4886\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 40s - loss: 0.4836 - acc: 0.8204 - val_loss: 2.2700 - val_acc: 0.4772\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 39s - loss: 0.4693 - acc: 0.8287 - val_loss: 2.3021 - val_acc: 0.4748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e0c84cee80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_datagen.flow(x_train, y_train_onehot, batch_size=batch_size)\n",
    "                    , steps_per_epoch=n_train//batch_size\n",
    "                    , epochs=epochs\n",
    "                    , validation_data=test_datagen.flow(x_test, y_test_onehot, batch_size=batch_size)\n",
    "                    , validation_steps=n_test//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2395591638962347, 0.47877620322601711]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and evaluate model\n",
    "model.save_weights('./Model/simple model_epoch100.h5')\n",
    "model.evaluate_generator(test_datagen.flow(x_test, y_test_onehot, batch_size=batch_size), steps=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Python35-64bit\\lib\\site-packages\\keras\\preprocessing\\image.py:648: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (3589, 48, 48, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1483092521727705, 0.49375703864288545]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "test_datagen.fit(x_private)\n",
    "model.evaluate_generator(test_datagen.flow(x_private, y_private_onehot, batch_size=batch_size), steps=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
