{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import helper3 as helper\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Cropping2D, Conv2D, ZeroPadding2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.core import Flatten, Dropout, Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "import keras.backend as k\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import keras\n",
    "import h5py\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "seed = 1\n",
    "import h5py\n",
    "import pdb\n",
    "from sklearn.utils import class_weight\n",
    "from skimage import exposure\n",
    "import cv2\n",
    "\n",
    "#turn off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data, format, & preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotion_dict = {0:'angry', 1:'disgust', 2:'fear', 3:'happy', 4:'sad', 5:'surprise', 6:'neutral'}\n",
    "image_shape = (48,48,1)\n",
    "n_classes = len(emotion_dict)\n",
    "n_features = np.product(image_shape)\n",
    "\n",
    "# read in data\n",
    "file_path = './Data/Kaggle-FER/fer2013.csv'\n",
    "data_raw = helper.read_in_data(file_path) # data is a tuple of (x_list, y_list, usage_list)\n",
    "\n",
    "# convert data to numpy array\n",
    "data_formatted = helper.format(data_raw, image_shape, n_classes) # return tuple of (x_array, y_array, usage_list)\n",
    "\n",
    "# number of example for each class\n",
    "label, count = np.unique(data_formatted[1], return_counts=True)\n",
    "print(dict(zip(label, count)))\n",
    "\n",
    "# split into train & test sets. Test set = public, private set is used for final testing, to be consistent with the competition\n",
    "(x_train, y_train), (x_test, y_test), (x_private, y_private) = helper.create_train_test(data_formatted, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # take a random sample\n",
    "# n_sample = 100\n",
    "\n",
    "# x_train = x_train[0:n_sample]\n",
    "# y_train = y_train[0:n_sample]\n",
    "# x_test = x_test[0:n_sample]\n",
    "# y_test = y_test[0:n_sample]\n",
    "# x_private = x_private[0:n_sample]\n",
    "# y_private = y_private[0:n_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select certain class\n",
    "selected_classes = [3,4]\n",
    "n_sample = 50\n",
    "\n",
    "mask = np.isin(y_train, selected_classes).reshape(-1)\n",
    "# print('mask shape', mask.shape)\n",
    "x_train = x_train[mask][0:n_sample]\n",
    "y_train = y_train[mask][0:n_sample]\n",
    "\n",
    "mask = np.isin(y_test, selected_classes).reshape(-1)\n",
    "x_test = x_test[mask][0:n_sample]\n",
    "y_test = y_test[mask][0:n_sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set {3: 30, 4: 20}\n",
      "validation set {3: 32, 4: 18}\n"
     ]
    }
   ],
   "source": [
    "# number of example for each class\n",
    "label, count = np.unique(y_train, return_counts=True)\n",
    "print('training set', dict(zip(label, count)))\n",
    "\n",
    "label, count = np.unique(y_test, return_counts=True)\n",
    "print('validation set', dict(zip(label, count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    rescale_factor = 255\n",
    "    train_datagen = ImageDataGenerator(featurewise_center=True\n",
    "                                       , featurewise_std_normalization=True\n",
    "                                       , horizontal_flip=True\n",
    "#                                        , preprocessing_function=exposure.equalize_hist\n",
    "                                       , width_shift_range=0.2\n",
    "#                                        , height_shift_range=0.2, rotation_range=.45\n",
    "#                                        , shear_range=0.2, zoom_range=0.2\n",
    "                                      )\n",
    "#     pdb.set_trace()\n",
    "    train_datagen.fit(x_train)\n",
    "\n",
    "    # print('x_train[0]', x_train[index])\n",
    "    # for index in range(len(x_train)):\n",
    "    #     np.savetxt('x_train_' + str(index) + '.csv', x_train[index], delimiter=',')\n",
    "\n",
    "    #     for batch in train_datagen.flow(np.reshape(x_train[index], (1,*image_shape))\n",
    "    #                                     , batch_size=1):\n",
    "    #         np.savetxt('x_train_preprocessed_' + str(index) + '.csv', np.reshape(batch, image_shape), delimiter=',')\n",
    "    #     #     print(type(batch))\n",
    "    #     #     print(batch.shape)\n",
    "    #         break\n",
    "\n",
    "\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adapthistequal(img):\n",
    "    return exposure.equalize_adapthist(np.reshape(img, (48,48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe92a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocess: normalized\n",
    "train_datagen = ImageDataGenerator(featurewise_center=True\n",
    "                                       , featurewise_std_normalization=True\n",
    "                                       , horizontal_flip=True\n",
    "#                                        , preprocessing_function=exposure.equalize_hist\n",
    "#                                        , width_shift_range=0.2\n",
    "#                                        , height_shift_range=0.2\n",
    "#                                        , rotation_range=.45\n",
    "#                                        , shear_range=0.2\n",
    "                                        , zoom_range=0.2\n",
    "                                      )\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "# test_datagen.fit(x_train)\n",
    "\n",
    "\n",
    "# visual data\n",
    "index = 8\n",
    "\n",
    "img_array = np.reshape(x_train[index], (48,48))\n",
    "plt.imshow(img_array, cmap='gray')\n",
    "print(emotion_dict[y_train[index,0]])\n",
    "\n",
    "# after preprocess\n",
    "i = 0\n",
    "for batch in train_datagen.flow(np.reshape(x_train[index], (1,*image_shape))\n",
    "                                , batch_size=32, save_to_dir='preview', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "y_train_onehot = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, n_classes)\n",
    "y_private_onehot = keras.utils.to_categorical(y_private, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 48, 48, 1)\n",
      "(50, 1)\n",
      "(50, 7)\n",
      "(50, 48, 48, 1)\n",
      "(50, 1)\n",
      "(50, 7)\n",
      "(3589, 48, 48, 1)\n",
      "(3589, 1)\n",
      "(3589, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train_onehot.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_test_onehot.shape)\n",
    "print(x_private.shape)\n",
    "print(y_private.shape)\n",
    "print(y_private_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 256\n",
    "n_train = len(x_train)\n",
    "n_test = len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_crop (Cropping2D)     (None, 42, 42, 1)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv (Conv2D)         (None, 42, 42, 32)        320       \n",
      "_________________________________________________________________\n",
      "block1_bn (BatchNormalizatio (None, 42, 42, 32)        128       \n",
      "_________________________________________________________________\n",
      "block1_relu (LeakyReLU)      (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "block2_pad (ZeroPadding2D)   (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv (Conv2D)         (None, 20, 20, 32)        16416     \n",
      "_________________________________________________________________\n",
      "block2_bn (BatchNormalizatio (None, 20, 20, 32)        128       \n",
      "_________________________________________________________________\n",
      "block2_relu (LeakyReLU)      (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "block2_pool (AveragePooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv (Conv2D)         (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "block3_bn (BatchNormalizatio (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "block3_relu (LeakyReLU)      (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "block3_pool (AveragePooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "block4_flat (Flatten)        (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "block4_dropout (Dropout)     (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "block4_fc (Dense)            (None, 3072)              4918272   \n",
      "_________________________________________________________________\n",
      "block4_relu (LeakyReLU)      (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "block4_out (Dense)           (None, 7)                 21511     \n",
      "_________________________________________________________________\n",
      "block4_softmax (Activation)  (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 5,008,295\n",
      "Trainable params: 5,008,039\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = '1st_place'\n",
    "kernel_initializer = TruncatedNormal(seed=1)\n",
    "kernel_regularizer = None\n",
    "batch_norm = True\n",
    "\n",
    "model = Sequential(name=model_name)\n",
    "model.add(Cropping2D(cropping=3, input_shape=image_shape, name='block1_crop'))\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_initializer=kernel_initializer\n",
    "            , kernel_regularizer=kernel_regularizer\n",
    "            , name='block1_conv'))\n",
    "if batch_norm==True:\n",
    "    model.add(BatchNormalization(axis=3, name='block1_bn'))\n",
    "model.add(LeakyReLU(name='block1_relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2), padding='valid', name='block1_pool'))\n",
    "\n",
    "model.add(ZeroPadding2D(padding=1, name='block2_pad'))\n",
    "model.add(Conv2D(32, (4,4), padding='valid', kernel_initializer=kernel_initializer\n",
    "            , kernel_regularizer=kernel_regularizer\n",
    "            , name='block2_conv'))\n",
    "if batch_norm==True:\n",
    "    model.add(BatchNormalization(axis=3, name='block2_bn'))\n",
    "model.add(LeakyReLU(name='block2_relu'))\n",
    "model.add(AveragePooling2D((2,2), strides=(2,2), padding='valid', name='block2_pool'))\n",
    "\n",
    "model.add(Conv2D(64, (5,5), padding='same', kernel_initializer=kernel_initializer\n",
    "            , kernel_regularizer=kernel_regularizer\n",
    "            , name='block3_conv'))\n",
    "if batch_norm==True:\n",
    "    model.add(BatchNormalization(axis=3, name='block3_bn'))\n",
    "model.add(LeakyReLU(name='block3_relu'))\n",
    "model.add(AveragePooling2D((2,2), strides=(2,2), padding='valid', name='block3_pool'))\n",
    "\n",
    "model.add(Flatten(name='block4_flat'))\n",
    "# TODO is this where dropout should be?\n",
    "model.add(Dropout(0.2, seed=seed, name='block4_dropout'))\n",
    "model.add(Dense(3072, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer, name='block4_fc'))\n",
    "# if batch_norm==True:\n",
    "    # model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(name='block4_relu'))\n",
    "# TODO svm Activations function\n",
    "model.add(Dense(n_classes, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer, name='block4_out'))\n",
    "# if batch_norm==True:\n",
    "    # model.add(BatchNormalization())\n",
    "model.add(Activation('softmax', name='block4_softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block0_crop (Cropping2D)     (None, 42, 42, 1)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv (Conv2D)         (None, 42, 42, 16)        160       \n",
      "_________________________________________________________________\n",
      "block1_bn (BatchNormalizatio (None, 42, 42, 16)        64        \n",
      "_________________________________________________________________\n",
      "block1_relu (LeakyReLU)      (None, 42, 42, 16)        0         \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 21, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv (Conv2D)         (None, 21, 21, 32)        12832     \n",
      "_________________________________________________________________\n",
      "block1_bn (BatchNormalizatio (None, 21, 21, 32)        128       \n",
      "_________________________________________________________________\n",
      "block1_relu (LeakyReLU)      (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "block2_pad (ZeroPadding2D)   (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv (Conv2D)         (None, 9, 9, 32)          16416     \n",
      "_________________________________________________________________\n",
      "block2_bn (BatchNormalizatio (None, 9, 9, 32)          128       \n",
      "_________________________________________________________________\n",
      "block2_relu (LeakyReLU)      (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "block2_pool (AveragePooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv (Conv2D)         (None, 4, 4, 64)          51264     \n",
      "_________________________________________________________________\n",
      "block3_bn (BatchNormalizatio (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "block3_relu (LeakyReLU)      (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "block3_pool (AveragePooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "block4_flat (Flatten)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "block4_dropout (Dropout)     (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "block4_fc (Dense)            (None, 3072)              789504    \n",
      "_________________________________________________________________\n",
      "block4_relu (LeakyReLU)      (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "block4_out (Dense)           (None, 7)                 21511     \n",
      "_________________________________________________________________\n",
      "block4_softmax (Activation)  (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 892,263\n",
      "Trainable params: 891,975\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = '1st_place'\n",
    "kernel_initializer = TruncatedNormal(seed=1)\n",
    "kernel_regularizer = None\n",
    "batch_norm = True\n",
    "\n",
    "model = Sequential(name=model_name)\n",
    "model.add(Cropping2D(cropping=3, input_shape=image_shape, name='block0_crop'))\n",
    "\n",
    "model.add(Conv2D(16, (3,3), padding='same', kernel_initializer=kernel_initializer\n",
    "            , kernel_regularizer=kernel_regularizer\n",
    "            , name='block1_conv'))\n",
    "if batch_norm==True:\n",
    "    model.add(BatchNormalization(axis=3, name='block1_bn'))\n",
    "model.add(LeakyReLU(name='block1_relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2), padding='valid', name='block1_pool'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (5,5), padding='same', kernel_initializer=kernel_initializer\n",
    "            , kernel_regularizer=kernel_regularizer\n",
    "            , name='block1_conv'))\n",
    "if batch_norm==True:\n",
    "    model.add(BatchNormalization(axis=3, name='block1_bn'))\n",
    "model.add(LeakyReLU(name='block1_relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2), padding='valid', name='block1_pool'))\n",
    "\n",
    "model.add(ZeroPadding2D(padding=1, name='block2_pad'))\n",
    "model.add(Conv2D(32, (4,4), padding='valid', kernel_initializer=kernel_initializer\n",
    "            , kernel_regularizer=kernel_regularizer\n",
    "            , name='block2_conv'))\n",
    "if batch_norm==True:\n",
    "    model.add(BatchNormalization(axis=3, name='block2_bn'))\n",
    "model.add(LeakyReLU(name='block2_relu'))\n",
    "model.add(AveragePooling2D((2,2), strides=(2,2), padding='valid', name='block2_pool'))\n",
    "\n",
    "model.add(Conv2D(64, (5,5), padding='same', kernel_initializer=kernel_initializer\n",
    "            , kernel_regularizer=kernel_regularizer\n",
    "            , name='block3_conv'))\n",
    "if batch_norm==True:\n",
    "    model.add(BatchNormalization(axis=3, name='block3_bn'))\n",
    "model.add(LeakyReLU(name='block3_relu'))\n",
    "model.add(AveragePooling2D((2,2), strides=(2,2), padding='valid', name='block3_pool'))\n",
    "\n",
    "model.add(Flatten(name='block4_flat'))\n",
    "# TODO is this where dropout should be?\n",
    "model.add(Dropout(0.2, seed=seed, name='block4_dropout'))\n",
    "model.add(Dense(3072, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer, name='block4_fc'))\n",
    "# if batch_norm==True:\n",
    "    # model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(name='block4_relu'))\n",
    "# TODO svm Activations function\n",
    "model.add(Dense(n_classes, kernel_initializer=kernel_initializer, kernel_regularizer=kernel_regularizer, name='block4_out'))\n",
    "# if batch_norm==True:\n",
    "    # model.add(BatchNormalization())\n",
    "model.add(Activation('softmax', name='block4_softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st place model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Python35-64bit\\lib\\site-packages\\keras\\preprocessing\\image.py:648: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (50, 48, 48, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Block1_Crop (Cropping2D)     (None, 42, 42, 1)         0         \n",
      "_________________________________________________________________\n",
      "Block1_Conv (Conv2D)         (None, 42, 42, 32)        832       \n",
      "_________________________________________________________________\n",
      "Block1_Pool (MaxPooling2D)   (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "Block2_Pad (ZeroPadding2D)   (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "Block2_Conv (Conv2D)         (None, 20, 20, 32)        16416     \n",
      "_________________________________________________________________\n",
      "Block2_Pool (AveragePooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "Block3_Conv (Conv2D)         (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "Block3_Pool (AveragePooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "Block4_Flat (Flatten)        (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "Block4_Dropout (Dropout)     (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "Block4_FC (Dense)            (None, 3072)              4918272   \n",
      "_________________________________________________________________\n",
      "Block4_Out (Dense)           (None, 7)                 21511     \n",
      "=================================================================\n",
      "Total params: 5,008,295\n",
      "Trainable params: 5,008,295\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When using a generator for validation data, you must specify a value for `validation_steps`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9d7ef04d7e40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                     \u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                     , callbacks=callbacks)\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# inital_weights = model.get_weights()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python35-64bit\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python35-64bit\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1122\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python35-64bit\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python35-64bit\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1803\u001b[0m                    hasattr(validation_data, '__next__'))\n\u001b[0;32m   1804\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mval_gen\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1805\u001b[1;33m             raise ValueError('When using a generator for validation data, '\n\u001b[0m\u001b[0;32m   1806\u001b[0m                              \u001b[1;34m'you must specify a value for '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1807\u001b[0m                              '`validation_steps`.')\n",
      "\u001b[1;31mValueError\u001b[0m: When using a generator for validation data, you must specify a value for `validation_steps`."
     ]
    }
   ],
   "source": [
    "# # preprocess\n",
    "# rescale_factor = 255\n",
    "# train_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True\n",
    "#                                    , rotation_range=45., width_shift_range=0.2, height_shift_range=0.2\n",
    "#                                    , horizontal_flip=True, rescale=1./rescale_factor)\n",
    "# train_datagen.fit(x_train)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True\n",
    "#                                   , rescale=1./rescale_factor)\n",
    "# test_datagen.fit(x_train)\n",
    "\n",
    "\n",
    "# preprocess\n",
    "rescale_factor = 255\n",
    "train_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True\n",
    "                                   , horizontal_flip=True)\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "test_datagen.fit(x_train)\n",
    "\n",
    "# build model\n",
    "model_name = '1st_place'\n",
    "model = Sequential(name=model_name)\n",
    "model.add(Cropping2D(cropping=3, input_shape=image_shape, name='Block1_Crop'))\n",
    "model.add(Conv2D(32, (5,5), padding='same', activation='relu', kernel_initializer='TruncatedNormal', name='Block1_Conv'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2), padding='valid', name='Block1_Pool'))\n",
    "\n",
    "model.add(ZeroPadding2D(padding=1, name='Block2_Pad'))\n",
    "model.add(Conv2D(32, (4,4), padding='valid', activation='relu', kernel_initializer='TruncatedNormal', name='Block2_Conv'))\n",
    "model.add(AveragePooling2D((2,2), strides=(2,2), padding='valid', name='Block2_Pool'))\n",
    "\n",
    "model.add(Conv2D(64, (5,5), padding='same', activation='relu', kernel_initializer='TruncatedNormal', name='Block3_Conv'))\n",
    "model.add(AveragePooling2D((2,2), strides=(2,2), padding='valid', name='Block3_Pool'))\n",
    "\n",
    "model.add(Flatten(name='Block4_Flat'))\n",
    "# TODO is this where dropout should be?\n",
    "model.add(Dropout(0.2, name='Block4_Dropout'))\n",
    "model.add(Dense(3072, activation='relu', kernel_initializer='TruncatedNormal', name='Block4_FC'))\n",
    "# TODO svm activation function\n",
    "model.add(Dense(n_classes, activation='softmax', kernel_initializer='TruncatedNormal', name='Block4_Out'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "sgd = optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
    "checkpointer = ModelCheckpoint(filepath='./Model/1st_place_weights.hdf5', verbose=1, save_best_only=True)\n",
    "callbacks = [checkpointer, reduce_lr]\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    "history = model.fit_generator(train_datagen.flow(x_train, y_train_onehot, batch_size=batch_size)\n",
    "                    , steps_per_epoch=n_train//batch_size\n",
    "                    , epochs=epochs\n",
    "                    , validation_data=test_datagen.flow(x_test, y_test_onehot, batch_size=batch_size)\n",
    "                    , validation_steps=n_test//batch_size\n",
    "                    , callbacks=callbacks)\n",
    "\n",
    "# inital_weights = model.get_weights()\n",
    "\n",
    "# # fit model\n",
    "# epoch_sets = 2\n",
    "# epochs = 1\n",
    "# batch_size = 50\n",
    "# weights = []\n",
    "\n",
    "# for es in range(epoch_sets):\n",
    "#     # get current lr\n",
    "#     lr = k.get_value(sgd.lr)\n",
    "#     print('epoch set:', es, 'lr value:', lr)\n",
    "    \n",
    "#     # fit model\n",
    "#     history = model.fit_generator(train_datagen.flow(x_train, y_train_onehot, batch_size=batch_size)\n",
    "#                         , steps_per_epoch=n_train//batch_size\n",
    "#                         , epochs=epochs\n",
    "#                         , validation_data=test_datagen.flow(x_test, y_test_onehot, batch_size=batch_size)\n",
    "#                         , validation_steps=n_test//batch_size)\n",
    "    \n",
    "#     # for every x number of epochs\n",
    "#     # check weights:updates ratio: histograms, store position\n",
    "#     weights.append(model.get_weights())\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # plot loss, train & val acc\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     # decay lr by half if running average loss (across y number of epochs) has stalled\n",
    "#     lr = lr / 2\n",
    "#     k.set_value(sgd.lr, lr)\n",
    "    \n",
    "    \n",
    "#     # after z number of epochs\n",
    "#     # activation distribution (histograms)\n",
    "    \n",
    "    \n",
    "#     # visualize layers\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# visualize loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to understand BaseLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # compile model\n",
    "    sgd = optimizers.SGD(momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "    # callbacks\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
    "    checkpointer = ModelCheckpoint(filepath='./Model/1st_place_weights.hdf5', verbose=1, save_best_only=True)\n",
    "    callbacks = [checkpointer, reduce_lr]\n",
    "\n",
    "    batch_size = 256\n",
    "    epochs = 50\n",
    "    \n",
    "    pdb.set_trace()\n",
    "    history = model.fit_generator(train_datagen.flow(x_train, y_train_onehot, batch_size=batch_size)\n",
    "                        , steps_per_epoch=n_train//batch_size\n",
    "                        , epochs=epochs\n",
    "                        , validation_data=test_datagen.flow(x_test, y_test_onehot, batch_size=batch_size)\n",
    "                        , validation_steps=n_test//batch_size\n",
    "                        , callbacks=callbacks)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
